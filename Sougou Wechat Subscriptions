'''
!/usr/bin/python
Author: LUO Chen
Written on 2016/06/23
Take the keyword '米其林' as example, this crawler works in the login circumstance.
The number of 'Thumb Up' and 'Read' is easy to crawl, I would expose the method another day.
'''

from lxml import etree
import requests, re

url = 'http://weixin.sogou.com/weixin?oq=&query=%E7%B1%B3%E5%85%B6%E6%9E%97&_sug_type_=1&sut=0&lkt=0%2C0%2C0&ri=1&_sug_=n&type=2\
&sst0=1466681336411&page=1&ie=utf8&p=40040108&dp=1&w=01015002&dr=1'
# Input page number you want to crawl
page_num = int(raw_input('How many pages do you want? '))

for i in range(1, page_num + 1):
    # Replace the URL 
    link = re.sub('&page=\d+', '&page=%d' %i, url)
    html = requests.get(link)
    selector = etree.HTML(html.text)
    title_field = selector.xpath('//div[@class = "wx-rb wx-rb3"]/div[@class = "txt-box"]/h4')
    for each in title_field:
        title = each.xpath('string(.)')
        # Title of the article
        print title
        href = each.xpath('a/@href')[0]
        sub_html = requests.get(href)
        selector_1 = etree.HTML(sub_html.text)
        content_field = selector_1.xpath('//div[@class="rich_media_inner"]/div[@id="page-content"]/div[@id="img-content"]/div[@class="rich_media_content "]')
        for paragraph in content_field:
            # Content of the article
            print paragraph.xpath('string(.)')
