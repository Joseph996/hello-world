from bs4 import BeautifulSoup
from urllib2 import urlopen
from time import sleep

base_url = "http://www.chicagoreader.com"

# 避免后期重复写这两行代码
def make_soup(url):
    html = urlopen(url).read()
    return BeautifulSoup(html, "lxml")

# 目录页的链接获取
def get_detail_links(url_1):
    soup = make_soup(url_1)
    boccat = soup.find("dl", "boccat")
    detail_links = [base_url + dd.a["href"] for dd in boccat.find_all("dd")]
    return detail_links

# 具体信息页的数据采集
def get_winner_runners(url_2):
    soup = make_soup(url_2)
    detail = soup.find("h1", "headline").string
    winner = [h2.string for h2 in soup.findAll("h2", "boc1")]
    runners = [h2.string for h2 in soup.findAll("h2", "boc2")]
    return {"detail": detail,
            "detail_url": url_2,
            "winner": winner,
            "runner": runners}

# 启动爬虫
if __name__ == '__main__':
    food_and_drink = ("http://www.chicagoreader.com/chicago/best-of-chicago-2011-food-drink/BestOf?oid=4106228")
    
    detail_links = get_detail_links(food_and_drink)
    print detail_links
    
    data = []  # 列表内将嵌套字典
    for detail_link in detail_links:
        winner_runners = get_winner_runners(detail_link)
        data.append(winner_runners)
        sleep(1)

    print data
